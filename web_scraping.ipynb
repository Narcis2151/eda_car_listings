{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define makes and their respective ids\n",
    "\n",
    "makes = {\n",
    "    \"Audi\": \"1900\", # done\n",
    "    \"Volkswagen\": \"25200\", # done\n",
    "    \"Skoda\": \"22900\", # done\n",
    "    \"Seat\": \"22500\", # done\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def scrape_page_for_make(make, page_number):\n",
    "    # Create a new browser instance\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "    # Create the base url\n",
    "    link = f\"https://suchen.mobile.de/fahrzeuge/search.html?dam=false&isSearchRequest=true&p=%3A30000&s=Car&sb=rel&vc=Car&ms={make}&lang=en\"\n",
    "\n",
    "    if page_number > 1:\n",
    "        link += f\"&pageNumber={page_number}\"\n",
    "    print(f\"Starting to scrape {link}\")\n",
    "\n",
    "    try:\n",
    "        driver.get(link)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "\n",
    "        # Try to handle the cookie consent pop-up\n",
    "        try:\n",
    "            cookie_button = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (By.XPATH, \"//button[contains(text(), 'Accept')]\")\n",
    "                )\n",
    "            )\n",
    "            cookie_button.click()\n",
    "            print(\"Cookie consent accepted.\")\n",
    "        except Exception as e:\n",
    "            print(\"No cookie consent pop-up or unable to locate it:\", e)\n",
    "\n",
    "        # Pause to let the page fully load\n",
    "        time.sleep(1)\n",
    "\n",
    "        listings_source = driver.page_source\n",
    "        listings_soup = BeautifulSoup(listings_source, \"html.parser\")\n",
    "        print(\"Done scraping base link\")\n",
    "\n",
    "    finally:\n",
    "        # Always close the driver\n",
    "        driver.quit()\n",
    "\n",
    "    return listings_soup"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_listing_links_from_soup(soup):\n",
    "    listings_article = soup.find_all(\"article\", attrs={\"data-testid\": \"result-list-container\"})[0]\n",
    "    listings = listings_article.find_all(\"div\", recursive=False)[1:]\n",
    "    listings_links = [\n",
    "        listing.find_all(\"a\")[0][\"href\"] for listing in listings if listing.find_all(\"a\")\n",
    "    ]\n",
    "    listings_links = [\n",
    "        \"https://suchen.mobile.de\" + link for link in listings_links\n",
    "    ]\n",
    "    return listings_links"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Scrape the first 25 pages for each make\n",
    "make_links = {}\n",
    "for make, make_id in makes.items():\n",
    "    make_links[make] = []\n",
    "    for page_number in range(1, 51):\n",
    "        soup = scrape_page_for_make(make_id, page_number)\n",
    "        links = extract_listing_links_from_soup(soup)\n",
    "        make_links[make].extend(links)\n",
    "        time.sleep(1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the links to a pickle file\n",
    "with open(\"./data/make_links.pkl\", \"wb\") as f:\n",
    "    pickle.dump(make_links, f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_tech_data_from_listing_link(listing_link):\n",
    "    # Create a new browser instance for the listing\n",
    "    driver = webdriver.Chrome(\n",
    "        service=ChromeService(ChromeDriverManager().install())\n",
    "    )\n",
    "    try:\n",
    "        driver.get(listing_link)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "\n",
    "        # Try to handle the cookie consent pop-up\n",
    "        try:\n",
    "            cookie_button = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (By.XPATH, \"//button[contains(text(), 'Accept')]\")\n",
    "                )\n",
    "            )\n",
    "            cookie_button.click()\n",
    "            # print(\"Cookie consent accepted.\")\n",
    "        except Exception as e:\n",
    "            print(\"No cookie consent pop-up or unable to locate it:\", e)\n",
    "\n",
    "        # Pause to let the page fully load\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Scrape the page content\n",
    "        car_page = driver.page_source\n",
    "        car_soup = BeautifulSoup(car_page, \"html.parser\")\n",
    "        # print(\"Done scraping car page\")\n",
    "\n",
    "    finally:\n",
    "        # Always close the driver\n",
    "        driver.quit()\n",
    "    #Extract the price\n",
    "    try:\n",
    "        car_price_div = car_soup.find_all(\"div\", attrs={\"data-testid\": \"vip-price-label\"})[0]\n",
    "        car_price = car_price_div.find_all(\"div\")[0].text\n",
    "        # Extract the technical data\n",
    "        car_data = car_soup.find_all(\"article\", attrs={\"data-testid\": \"vip-technical-data-box\"})[0]\n",
    "        car_data = car_data.find_all(\"dl\")[0]\n",
    "        # extract all dt and dd tags\n",
    "        car_data = car_data.find_all([\"dt\", \"dd\"])\n",
    "        # zip them together\n",
    "        car_data = list(zip(car_data[::2], car_data[1::2]))\n",
    "        # make technical_data a dictionary\n",
    "        car_data = {dt.text: dd.text for dt, dd in car_data}\n",
    "        return car_data, car_price\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting technical data for {listing_link}: {e}\")\n",
    "        return None, None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "technical_data = {}\n",
    "for make, links in make_links.items():\n",
    "    technical_data[make] = []\n",
    "    for link in tqdm(links):\n",
    "        data, price = extract_tech_data_from_listing_link(link)\n",
    "        if data is None or price is None:\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "        data = dict(data)\n",
    "        data[\"price\"] = price\n",
    "        technical_data[make].append(data)\n",
    "        time.sleep(1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"./data/technical_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(technical_data, f)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
